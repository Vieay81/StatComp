---
title: "A-20020-2020-11-10"
output: html_document
---
## Question
Exercises 8.3 and experiments(page 243, Statistical Computating with R).  

## Answer
#### Exercise 8.3 
**Solution:**

**Approximate permutation test procedure**

1.Compute the observed test statistic $\hat\theta(X,Y)=\hat\theta(Z,\nu)=\max(c(outx,outy))$.

2.For each replicate, indexed $b=1,...,B$:

(a)Generate a random permutation $\pi_b=\pi(\nu)$.

(b)Compute the statistic $\hat\theta^{(b)}=\hat\theta^*(Z,\pi_b)$.

3.If large values of $\hat\theta$ support the alternative, compute the ASL (the empirical p-value) by
\[
\hat p=\frac{1+\sum_{b=1}^BI(\hat\theta^{(b)})\ge\hat\theta}{B+1}.
\]
For a lower-tail or two-tail test test test $\hat p$is computed in a similar way.

4.Reject $H_0$at significant level $\alpha$ if $\hat p\le\alpha$.

```{r}
counttest <- function(x, y)
{
  X <- x - mean(x)
  Y <- y - mean(y)
  outx <- sum(X > max(Y)) + sum(X < min(Y))
  outy <- sum(Y > max(X)) + sum(Y < min(X))
  max(c(outx, outy))
}

n1 <- 20
n2 <- 30
mu1 <- 1
mu2 <- 0
sigma1 <- sigma2 <- 1
B <- 1000
m <- 100
reject <- 0
for (i in 1:m)
{
  x1 <- rnorm(n1, mu1, sigma1)
  x2 <- rnorm(n2, mu2, sigma2)
  z <- c(x1, x2)
  t0 <- counttest(x1, x2)
  t <- replicate(B, expr = {
    k <- sample(1:length(z), size = length(x1), replace = F)
    x <- z[k]
    y <- z[-k]
    counttest(x, y)
  })
  p <- mean(c(t0, t) >= t0)
  reject <- reject + (p < .05)
}
reject / m
```
The output of reject proportion is close to $\alpha=0.05$, which indicates that the new method based on permutation test is applicable.

#### Experiment
```{r}
library(RANN)
library(boot)
library(energy)
library(Ball)
Tn <- function(z, ix, sizes,k) 
{
  n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
  if(is.vector(z)) z <- data.frame(z,0);
  z <- z[ix, ];
  NN <- nn2(data = z, k = k+1)
  block1 <- NN$nn.idx[1:n1,-1]
  block2 <- NN$nn.idx[(n1+1):n,-1]
  i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
  (i1 + i2) / (k * n)
}

# Unequal variances and equal expectations
n1 <- 50
n2 <- 50
mu1 <- 0
mu2 <- 0
sigma1 <- 1
sigma2 <- 4
m <- 1e3
k <- 3
R <- 999 
n <- n1 + n2
N = c(n1,n2)
eqdist.nn <- function(z,sizes,k)
{
  boot.obj <- boot(data = z, statistic = Tn, R = R, sim = "permutation", sizes = sizes, k = k)
  ts <- c(boot.obj$t0, boot.obj$t)
  p.value <- mean(ts >= ts[1])
  list(statistic = ts[1], p.value = p.value)
}
p.values <- matrix(NA, m ,3)
for(i in 1:m)
{
  x <- matrix(rnorm(n1, mu1, sigma1), ncol = 1)
  y <- matrix(rnorm(n2, mu2, sigma2), ncol = 1)
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z, N, k)$p.value
  p.values[i,2] <- eqdist.etest(z, sizes = N, R = R)$p.value
  p.values[i,3] <- bd.test(x = x, y = y, R = 999, seed = i*1165)$p.va
}
alpha <- .05;
power1 <- colMeans(p.values < alpha)
```
```{r}
# Unequal variances and unequal expectations
n1 <- 50
n2 <- 50
mu1 <- 0
mu2 <- 5
sigma1 <- 1
sigma2 <- 4
m <- 1e3
k <- 3
R <- 999 
n <- n1 + n2
N = c(n1,n2)
eqdist.nn <- function(z,sizes,k)
{
  boot.obj <- boot(data = z, statistic = Tn, R = R, sim = "permutation", sizes = sizes, k = k)
  ts <- c(boot.obj$t0, boot.obj$t)
  p.value <- mean(ts >= ts[1])
  list(statistic = ts[1], p.value = p.value)
}
p.values <- matrix(NA, m ,3)
for(i in 1:m)
{
  x <- matrix(rnorm(n1, mu1, sigma1), ncol = 1)
  y <- matrix(rnorm(n2, mu2, sigma2), ncol = 1)
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z, N, k)$p.value
  p.values[i,2] <- eqdist.etest(z, sizes = N, R = R)$p.value
  p.values[i,3] <- bd.test(x = x, y = y, R = 999, seed = i*7864)$p.va
}
alpha <- .05;
power2 <- colMeans(p.values < alpha)
```
```{r}
# Non-normal distributions
n1 <- 50
n2 <- 50
mu1 <- 0
mu2 <- 5
sigma1 <- 1
sigma2 <- 4
m <- 1e3
k <- 3
R <- 999 
n <- n1 + n2
N = c(n1,n2)
eqdist.nn <- function(z,sizes,k)
{
  boot.obj <- boot(data = z, statistic = Tn, R = R, sim = "permutation", sizes = sizes, k = k)
  ts <- c(boot.obj$t0, boot.obj$t)
  p.value <- mean(ts >= ts[1])
  list(statistic = ts[1], p.value = p.value)
}
p.values <- matrix(NA, m ,3)
for(i in 1:m)
{
  x <- matrix(rt(n1, df = 1), ncol = 1)
  y <- matrix(c(rnorm(n2/2, mu1, sigma1), rnorm(n2/2, mu2, sigma2)), ncol = 1)
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z, N, k)$p.value
  p.values[i,2] <- eqdist.etest(z, sizes = N, R = R)$p.value
  p.values[i,3] <- bd.test(x = x, y = y, R = 999, seed = i*94654)$p.va
}
alpha <- .05;
power3 <- colMeans(p.values < alpha)
```
```{r}
# Unbalanced samples
n1 <- 50
n2 <- 5
mu1 <- 0
mu2 <- 5
sigma1 <- 1
sigma2 <- 4
m <- 1e3
k <- 3
R <- 999 
n <- n1 + n2
N = c(n1,n2)
eqdist.nn <- function(z,sizes,k)
{
  boot.obj <- boot(data = z, statistic = Tn, R = R, sim = "permutation", sizes = sizes, k = k)
  ts <- c(boot.obj$t0, boot.obj$t)
  p.value <- mean(ts >= ts[1])
  list(statistic = ts[1], p.value = p.value)
}
p.values <- matrix(NA, m ,3)
for(i in 1:m)
{
  x <- matrix(rnorm(n1, mu1, sigma1), ncol = 1)
  y <- matrix(rnorm(n2, mu2, sigma2), ncol = 1)
  z <- rbind(x,y)
  p.values[i,1] <- eqdist.nn(z, N, k)$p.value
  p.values[i,2] <- eqdist.etest(z, sizes = N, R = R)$p.value
  p.values[i,3] <- bd.test(x = x, y = y, R = 999, seed = i*78324)$p.va
}
alpha <- .05;
power4 <- colMeans(p.values < alpha)
```
The result is as follow:

|NN|Energy|Ball|
|---|---|---|
|`r power1[1]`|`r power1[2]`|`r power1[3]`|
|`r power2[1]`|`r power2[2]`|`r power2[3]`|
|`r power3[1]`|`r power3[2]`|`r power3[3]`|
|`r power4[1]`|`r power4[2]`|`r power4[3]`|

That indicates Energy test could deal with the Non-normal distributions problem and Unbalanced samples problem. In addition, the results of three methods are similar with the Unequal variances or expectations problem.